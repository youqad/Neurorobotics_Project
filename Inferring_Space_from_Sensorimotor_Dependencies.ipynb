{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inferring_Space_from_Sensorimotor_Dependencies.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/youqad/Neurorobotics_Project/blob/master/Inferring_Space_from_Sensorimotor_Dependencies.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "D6TQj1Jsbql6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inferring Space from Sensorimotor Dependencies\n",
        "\n",
        "\n",
        "## The Algorithm\n",
        "\n",
        "1. Proprioceptive input is separated from exteroceptive input by noting that proprioceptive input remains silent when no motor commands are given, whereas exteroceptive input changes because of environmental change.\n",
        "\n",
        "2. Estimation of the number of parameters needed to describe the variation in the exteroceptive inputs when only the environment changes. The algorithm issues no motor commands and calculates the covariance matrix of the observed environment-induced variations in sensory inputs. The dimension estimation is done by considering the eigenvalues of this covariance matrix. The eigenvalues $λ_i$ should fall into two classes: a class with values all equal to zero and a class with nonzero values. The two classes are separated by a clustering method (e.g. PCA). The number of nonzero eigenvalues is taken as the number of dimensions.\n",
        "\n",
        "3. Estimation of the number of parameters needed to describe the variation in the exteroceptive inputs when only the body moved. The environment is kept fixed, and the algorithm gives random motor commands. The covariance matrix of the resulting changes is observed and the dimension is estimated from the number of nonzero eigenvalues in the same way as before.\n",
        "\n",
        "4. Estimation of the number of parameters needed to describe the changes in exteroceptive inputs when both the body and the environment change. The environment is changed at random, and the organism gives random motor commands. The number of nonzero eigenvalues of the covariance matrix is obtained as before.\n",
        "\n",
        "## Simulation\n",
        "\n",
        "### Notations\n",
        "\n",
        "Notation|Meaning\n",
        "-|-\n",
        "$$Q ≝ (Q_1, \\ldots, Q_{3q})$$|positions of the joints\n",
        "$$P ≝ (P_1, \\ldots, P_{3p})$$|positions of the eyes\n",
        "$$a^θ_i, a^φ_i, a^ψ_i$$|Euler angles for the orientation of eye i\n",
        "$$Rot(a^θ_i, a^φ_i, a^ψ_i)$$|rotation matrix for eye i\n",
        "$$C_{i,k}$$|relative position of photosensor $k$ within eye $i$\n",
        "$$d ≝ (d_1, \\ldots,d_p)$$|apertures of diaphragms\n",
        "$$L ≝ (L_1,\\ldots,L_{3r})$$|positions of the lights\n",
        "$$θ ≝ (θ_1, \\ldots, θ_r)$$|luminances of the lights\n",
        "$$S^e_{i,k}$$|sensory input from exteroceptive sensor $k$ of eye $i$\n",
        "$$S^p_i$$|sensory input from proprioceptive sensor $i$\n",
        "$$M, E$$|motor command and environmental control vector\n",
        "\n",
        "\n",
        "### Computing the sensory inputs\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "(Q,P,a) &≝ σ(W_1 · σ(W_2 · M − μ_2)−μ_1)\\\\\n",
        "L &≝ σ(V_1 ·σ(V_2 · E − ν_2) − ν_1)\\\\\n",
        "∀1≤ k ≤ p', 1≤i≤p, \\quad S^e_{i,k} &≝ d_i \\sum\\limits_{ j } \\frac{θ_j}{\\Vert P_i + Rot(a_i^θ, a_i^φ, a_i^ψ) \\cdot C_{i,k} - L_j \\Vert^2}\\\\\n",
        "(S^p_i)_{1≤ i ≤ q'q} &≝ σ(U_1 · σ(U_2 · Q − τ_2) − τ_1)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "- $W_1, W_2, V_1, V_2, U_1, U_2$ are matrices with coefficients drawn randomly from a uniform distribution between $−1$ and $1$\n",
        "- the vectors $μ_1, μ_2, ν_1, ν_2, τ_1, τ_2$ too\n",
        "- $σ$ is an arbitrary nonlinearity (e.g. the hyperbolic tangent function)\n",
        "- the $C_{i,k}$ are drawn from a centered normal distribution whose variance (which can be understood as the size of the retina) is so that the sensory changes resulting from a rotation of the eye are of the same order of magnitude as the ones resulting from a translation of the eye\n",
        "- $θ$ and $d$ are constants drawn at random in the interval $[0.5, 1]$\n"
      ]
    },
    {
      "metadata": {
        "id": "9HUFh3SFMFZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fa2d6f64-1c5b-4a8e-9e89-bc23f18a60cd"
      },
      "cell_type": "code",
      "source": [
        "# /!\\ We're using Python 3\n",
        "\n",
        "import plotly\n",
        "import numpy as np\n",
        "import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "from scipy import stats\n",
        "from scipy import special\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plotly.offline.init_notebook_mode(connected=True)\n",
        "from IPython.core.display import display, HTML, Markdown\n",
        "# The polling here is to ensure that plotly.js has already been loaded before\n",
        "# setting display alignment in order to avoid a race condition.\n",
        "display(HTML(\n",
        "    '<script>'\n",
        "        'var waitForPlotly = setInterval( function() {'\n",
        "            'if( typeof(window.Plotly) !== \"undefined\" ){'\n",
        "                'MathJax.Hub.Config({ SVG: { font: \"STIX-Web\" }, displayAlign: \"center\" });'\n",
        "                'MathJax.Hub.Queue([\"setRenderer\", MathJax.Hub, \"SVG\"]);'\n",
        "                'clearInterval(waitForPlotly);'\n",
        "            '}}, 250 );'\n",
        "    '</script>'\n",
        "))\n",
        "\n",
        "# Colorscales\n",
        "def colorscale_list(cmap, number_colors, return_rgb_only=False):\n",
        "    cm = plt.get_cmap(cmap)\n",
        "    colors = [np.array(cm(i/number_colors)) for i in range(1, number_colors+1)]\n",
        "    rgb_colors_plotly = []\n",
        "    rgb_colors_only = []\n",
        "    for i, c in enumerate(colors):\n",
        "        col = 'rgb{}'.format(tuple(255*c[:-1]))\n",
        "        rgb_colors_only.append(col)\n",
        "        rgb_colors_plotly.append([i/number_colors, col])\n",
        "        rgb_colors_plotly.append([(i+1)/number_colors, col])\n",
        "    return rgb_colors_only if return_rgb_only else rgb_colors_plotly\n",
        "\n",
        "from scipy.io import loadmat, whosmat\n",
        "from numpy.random import randint\n",
        "\n",
        "def formatted(f): \n",
        "    return format(f, '.2f').rstrip('0').rstrip('.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script>var waitForPlotly = setInterval( function() {if( typeof(window.Plotly) !== \"undefined\" ){MathJax.Hub.Config({ SVG: { font: \"STIX-Web\" }, displayAlign: \"center\" });MathJax.Hub.Queue([\"setRenderer\", MathJax.Hub, \"SVG\"]);clearInterval(waitForPlotly);}}, 250 );</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OBB1NorIxcHW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Organism 1\n",
        "\n",
        "**Parameter**|**Value**\n",
        "-|-\n",
        "Dimension of motor commands|$40$\n",
        "Dimension of environmental control vector|$40$\n",
        "Dimension of proprioceptive inputs|$16 \\quad (= 4×4)$\n",
        "Dimension of exteroceptive inputs|$40 \\quad (= 2 × 20)$\n",
        "Number of eyes|$2$\n",
        "Number of joints|$4$\n",
        "Diaphragms|None\n",
        "Number of lights|$3$\n",
        "Light luminance|Fixed\n",
        "\n",
        "\n",
        "1. The arm has\n",
        "\n",
        "    - $4$ joints\n",
        "\n",
        "        - each of which has $4$ **proprioceptive** sensors (whose output depended on the position of the joint)\n",
        "    - $2$ eyes (for each of them: $3$ spatial and $3$ orientation coordinates)\n",
        "\n",
        "        - on which there are $20$ omnidirectionally sensitive photosensors (**exteroceptive**)\n",
        "2. the motor command is $40$-dimensional  \n",
        "\n",
        "3. the environment consists of:\n",
        "\n",
        "    - $3$ lights ($3$ spatial coordinates and $3$ luminance values for each of them)"
      ]
    },
    {
      "metadata": {
        "id": "gNAH3OkjMhZu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Rotation matrix computation\n",
        "\n",
        "def Rot(euler_angles):\n",
        "  R = np.empty((3,3))\n",
        "  c = np.cos(euler_angles)\n",
        "  s = np.sin(euler_angles)\n",
        "\n",
        "  # cf. https://en.wikipedia.org/wiki/Euler_angles#Rotation_matrix \n",
        "  R[0,0] = c[0]*c[2] - c[1]*s[0]*s[2]\n",
        "  R[0,1] = -c[0]*s[2] - c[1]*c[2]*s[0]\n",
        "  R[0,2] = s[0]*s[1]\n",
        "\n",
        "  R[1,0] = s[0]*c[2] + c[0]*c[1]*s[2]\n",
        "  R[1,1] = c[0]*c[1]*c[2] - s[0]*s[2]\n",
        "  R[1,2] = -c[0]*s[1]\n",
        "\n",
        "  R[2,0] = s[1]*s[2]\n",
        "  R[2,1] = -c[2]*s[1]\n",
        "  R[2,2] = c[1]\n",
        "\n",
        "  return R\n",
        "\n",
        "def computing_sensory_inputs(M, E):\n",
        "  Q, P, a = [arr.reshape([-1, 3]) \n",
        "             for arr in np.split(sigma(W_1.dot(sigma(W_2.dot(M)-mu_2)) - mu_1), \n",
        "                                 [3*nb_joints, 3*nb_joints+3*nb_eyes])]\n",
        "  L = sigma(V_1.dot(sigma(V_2.dot(E)-nu_2)) - nu_1).reshape([-1, 3])\n",
        "  Sp = sigma(U_1.dot(sigma(U_2.dot(Q.flatten())-tau_2)) - tau_1)\n",
        "  Se = np.array([d[i]*\n",
        "                 sum(theta[j]/np.linalg.norm(P[i]+Rot(a[i]).dot(C[i,k])-L[j])**2\n",
        "                     for j in range(nb_lights))\n",
        "                 for i in range(nb_eyes)\n",
        "                 for k in range(extero)])\n",
        "  return np.concatenate((Sp, Se))\n",
        "  \n",
        "def neighborhood_lin_approx(size, neighborhood_size=neighborhood_size):\n",
        "  rand_vect = np.random.normal(0, neighborhood_size, size)\n",
        "  rand_vect[np.abs(rand_vect) > neighborhood_size] = 0\n",
        "  return rand_vect\n",
        "\n",
        "def PCA(data):\n",
        "  cov_matrix = np.cov(data.T)\n",
        "  eig_val, eig_vect = np.linalg.eigh(cov_matrix)\n",
        "  \n",
        "  #print(cov_matrix)\n",
        "  #print([eig_val[i+1]/eig_val[i] for i in range(len(eig_val)-1)])\n",
        "  \n",
        "  max_ratio = np.argmax([eig_val[i+1]/eig_val[i] for i in range(len(eig_val)-1)])\n",
        "  \n",
        "  return len(eig_val[max_ratio+1:])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "250iJKGB9yjy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Parameters\n",
        "\n",
        "M_size = 40 #@param {type:\"slider\", min:35, max:45, step:1}\n",
        "E_size = 40 #@param {type:\"slider\", min:35, max:45, step:1}\n",
        "\n",
        "# Number of Joints / q\n",
        "nb_joints = 4 #@param {type:\"slider\", min:3, max:5, step:1}\n",
        "\n",
        "# Number of eyes / p\n",
        "nb_eyes = 2 #@param {type:\"slider\", min:2, max:5, step:1}\n",
        "\n",
        "# Number of lights / r\n",
        "nb_lights = 3 #@param {type:\"slider\", min:2, max:5, step:1}\n",
        "\n",
        "# Number of exteroceptive photosensors / p'\n",
        "extero = 20 #@param {type:\"slider\", min:15, max:25, step:1}\n",
        "\n",
        "# Number of proprioceptive sensors / q'\n",
        "proprio = 4 #@param {type:\"slider\", min:3, max:5, step:1}\n",
        "\n",
        "\n",
        "# Sensory inputs were generated from...\n",
        "nb_generating_motor_commands = 40 #@param {type:\"slider\", min:10, max:100, step:10}\n",
        "nb_generating_env_positions = 40 #@param {type:\"slider\", min:10, max:100, step:10}\n",
        "\n",
        "# Neighborhood size of the linear approximation:\n",
        "# Motor commands/Environmental positions drawn from normal distribution\n",
        "# with mean zero and standard deviation... \n",
        "neighborhood_size = 1e-8\n",
        "# (Coordinates differing from 0 by more than the std deviation are set equal to 0)\n",
        "\n",
        "sigma = np.tanh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KooVy0Q3ND7c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simulation(seed):\n",
        "  np.random.seed(seed)\n",
        "\n",
        "  # Random initializations\n",
        "\n",
        "  dim_mu1 = 3*nb_joints+3*nb_eyes+3*nb_eyes\n",
        "  W_1, mu_1 = 2*np.random.rand(dim_mu1, dim_mu1)-1, 2*np.random.rand(dim_mu1)-1\n",
        "  W_2, mu_2 = 2*np.random.rand(dim_mu1, M_size)-1, 2*np.random.rand(dim_mu1)-1\n",
        "\n",
        "  dim_nu1 = 3*nb_lights\n",
        "  V_1, nu_1 = 2*np.random.rand(dim_nu1, dim_nu1)-1, 2*np.random.rand(dim_nu1)-1\n",
        "  V_2, nu_2 = 2*np.random.rand(dim_nu1, E_size)-1, 2*np.random.rand(dim_nu1)-1\n",
        "\n",
        "  dim_tau1 = proprio*nb_joints\n",
        "  U_1, tau_1 = 2*np.random.rand(dim_tau1, dim_tau1)-1, 2*np.random.rand(dim_tau1)-1\n",
        "  U_2, tau_2 = 2*np.random.rand(dim_tau1, 3*nb_joints)-1, 2*np.random.rand(dim_tau1)-1\n",
        "\n",
        "  theta, d = .5*np.random.rand(nb_lights)+.5, .5*np.random.rand(nb_eyes)+.5\n",
        "\n",
        "  C = np.random.multivariate_normal(np.zeros(3), np.identity(3), (nb_eyes, extero))\n",
        "\n",
        "  M_0, E_0 = 10*np.random.rand(M_size)-5, 10*np.random.rand(E_size)-5\n",
        "\n",
        "\n",
        "  # Separating proprioceptive input from exteroceptive input\n",
        "  mask_proprio = np.array([computing_sensory_inputs(M_0,\n",
        "                                                    E_0+np.random.normal(0, neighborhood_size, E_size))\n",
        "                  for _ in range(nb_generating_env_positions)])\n",
        "  mask_proprio = np.all(mask_proprio == mask_proprio[0, :], axis=0)\n",
        "\n",
        "\n",
        "  # Number of parameters needed to describe the variations \n",
        "  # in the exteroceptive inputs when \n",
        "  # 1. only the environment changes\n",
        "  # 2. only the motor commands change\n",
        "  # 3. both change\n",
        "\n",
        "  env_variations = np.array([\n",
        "      computing_sensory_inputs(M_0,\n",
        "                               E_0+neighborhood_lin_approx(E_size))[~mask_proprio]\n",
        "      for _ in range(nb_generating_env_positions)])\n",
        "\n",
        "  mot_variations = np.array([\n",
        "      computing_sensory_inputs(M_0+neighborhood_lin_approx(M_size),\n",
        "                               E_0)[~mask_proprio]\n",
        "      for _ in range(nb_generating_motor_commands)])\n",
        "\n",
        "  env_mot_variations = np.array([\n",
        "      computing_sensory_inputs(M_0+neighborhood_lin_approx(M_size),\n",
        "                               E_0+neighborhood_lin_approx(E_size))[~mask_proprio]\n",
        "      for _ in range(nb_generating_env_positions*nb_generating_motor_commands)])\n",
        "\n",
        "  # Now PCA!\n",
        "\n",
        "  dim_env = PCA(env_variations)\n",
        "  dim_extero = PCA(mot_variations)\n",
        "  dim_env_extero = PCA(env_mot_variations)\n",
        "\n",
        "  table = '''\n",
        "  ||Number of parameters necessary to describe|\n",
        "  -|-|\n",
        "  Exteroceptive body|{}\n",
        "  Environment|{}\n",
        "  Body and Environment simultaneous changes|{}\n",
        "  Group of compensated movements|{}\n",
        "  '''.format(dim_extero, dim_env, dim_env_extero,\n",
        "             dim_env+dim_extero-dim_env_extero)\n",
        "\n",
        "  return table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7Dew8eyAZPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "a22b8c5a-6c1a-4d7d-f3ea-0264d60759a8"
      },
      "cell_type": "code",
      "source": [
        "for seed in range(8):\n",
        "  print(simulation(seed))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|8\n",
            "  Environment|3\n",
            "  Body and Environment simultaneous changes|11\n",
            "  Group of compensated movements|0\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|3\n",
            "  Environment|1\n",
            "  Body and Environment simultaneous changes|3\n",
            "  Group of compensated movements|1\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|5\n",
            "  Environment|7\n",
            "  Body and Environment simultaneous changes|9\n",
            "  Group of compensated movements|3\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|8\n",
            "  Environment|3\n",
            "  Body and Environment simultaneous changes|9\n",
            "  Group of compensated movements|2\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|9\n",
            "  Environment|2\n",
            "  Body and Environment simultaneous changes|7\n",
            "  Group of compensated movements|4\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|1\n",
            "  Environment|2\n",
            "  Body and Environment simultaneous changes|8\n",
            "  Group of compensated movements|-5\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|6\n",
            "  Environment|5\n",
            "  Body and Environment simultaneous changes|6\n",
            "  Group of compensated movements|5\n",
            "  \n",
            "\n",
            "  ||Number of parameters necessary to describe|\n",
            "  -|-|\n",
            "  Exteroceptive body|7\n",
            "  Environment|4\n",
            "  Body and Environment simultaneous changes|10\n",
            "  Group of compensated movements|1\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mnfEq252fcYZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}